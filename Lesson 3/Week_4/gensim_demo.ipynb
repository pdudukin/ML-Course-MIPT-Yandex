{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PDudukin\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\PDudukin\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(1265 documents, 14352 features, 87409 non-zero entries)\n",
      "Dictionary(14352 unique tokens: ['1890', 'unscientific', 'addictiveness', 'galactica', 'yellow']...)\n"
     ]
    }
   ],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"docword.xkcd.txt\", \"vocab.xkcd.txt\")\n",
    "print data\n",
    "dictionary = data.create_dictionary()\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.001*\"google\" + 0.001*\"car\" + 0.001*\"text\" + 0.001*\"spider\" + 0.001*\"turtle\" + 0.001*\"radio\" + 0.001*\"title\" + 0.001*\"male\" + 0.001*\"reporter\" + 0.001*\"accident\"\n",
      "Topic 1 : 0.006*\"figure\" + 0.002*\"stick\" + 0.002*\"labeled\" + 0.002*\"exhibit\" + 0.002*\"one\" + 0.002*\"map\" + 0.001*\"island\" + 0.001*\"part\" + 0.001*\"within\" + 0.001*\"text\"\n",
      "Topic 2 : 0.002*\"graph\" + 0.002*\"line\" + 0.001*\"paul\" + 0.001*\"ron\" + 0.001*\"number\" + 0.001*\"planet\" + 0.001*\"mark\" + 0.001*\"axis\" + 0.001*\"time\" + 0.001*\"gliese\"\n",
      "Topic 3 : 0.002*\"woman\" + 0.001*\"list\" + 0.001*\"link\" + 0.001*\"jelly\" + 0.001*\"bean\" + 0.001*\"found\" + 0.001*\"title\" + 0.001*\"text\" + 0.001*\"goggles\" + 0.001*\"acne\"\n",
      "Topic 4 : 0.023*\"man\" + 0.012*\"text\" + 0.012*\"person\" + 0.010*\"title\" + 0.009*\"woman\" + 0.008*\"guy\" + 0.006*\"one\" + 0.006*\"girl\" + 0.005*\"just\" + 0.005*\"two\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print \"Topic\", t, \":\", top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183237.291131\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print 2**(-perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183237.29114332184"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f09218b8da97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Добавление в модель новых документов, содержащихся в новом корупсе data2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.059890440998369626),\n",
       " (1, 0.056929517390626176),\n",
       " (2, 0.056301091660803312),\n",
       " (3, 0.056782480799248386),\n",
       " (4, 0.77009646915095253)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
